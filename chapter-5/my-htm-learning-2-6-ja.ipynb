{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hello_tm.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__doc__=\"\"\"\n",
    "このプログラムでは、以下のようなデモを行い、Temporal Memoryに直接アクセスする方法を示しています。 TMインスタンスの作成方法、ベクトルを使った学習方法、予測値の取得方法、そして は状態を検査します。\n",
    "\n",
    "このコードはシーケンス学習の非常にシンプルなバージョンを実行しています。 セルをカラムごとに表示します。TM は単純なシーケンス A->B->C->D->E で学習されます。\n",
    "\"\"\"\n",
    "\n",
    "from htm.bindings.sdr import SDR\n",
    "from htm.algorithms import TemporalMemory as TM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特定の方法でSDRを印刷するためのユーティリティルーチンです\n",
    "def formatBits(sdr):\n",
    "  s = ''\n",
    "  for c in range(sdr.size):\n",
    "    if c > 0 and c % 10 == 0:\n",
    "      s += ' '\n",
    "    s += str(sdr.dense.flatten()[c])\n",
    "  s += ' '\n",
    "  return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "\n",
      "このプログラムでは、以下のようなデモを行い、Temporal Memoryに直接アクセスする方法を示しています。 TMインスタンスの作成方法、ベクトルを使った学習方法、予測値の取得方法、そして は状態を検査します。\n",
      "\n",
      "このコードはシーケンス学習の非常にシンプルなバージョンを実行しています。 セルをカラムごとに表示します。TM は単純なシーケンス A->B->C->D->E で学習されます。\n",
      "\n",
      "################################################################################\n",
      "\n",
      "Creating the Temporal Memory\n"
     ]
    }
   ],
   "source": [
    "def printStateTM( tm ):\n",
    "    # 内部状態をトレースするのに便利\n",
    "    print(\"Active cells     \" + formatBits(tm.getActiveCells()))\n",
    "    print(\"Winner cells     \" + formatBits(tm.getWinnerCells()))\n",
    "    tm.activateDendrites(True)\n",
    "    print(\"Predictive cells \" + formatBits(tm.getPredictiveCells()))\n",
    "    print(\"Anomaly\", tm.anomaly * 100, \"%\")\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "print(\"################################################################################\")\n",
    "print(__doc__)\n",
    "print(\"################################################################################\")\n",
    "print(\"\")\n",
    "print(\"Creating the Temporal Memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal Memory Parameters\n",
      "version                   = 2\n",
      "numColumns                = 50\n",
      "cellsPerColumn            = 1\n",
      "activationThreshold       = 8\n",
      "initialPermanence         = 0.5\n",
      "connectedPermanence       = 0.5\n",
      "minThreshold              = 8\n",
      "maxNewSynapseCount        = 20\n",
      "permanenceIncrement       = 0.1\n",
      "permanenceDecrement       = 0\n",
      "predictedSegmentDecrement = 0\n",
      "maxSegmentsPerCell        = 255\n",
      "maxSynapsesPerSegment     = 255\n"
     ]
    }
   ],
   "source": [
    "tm = TM(columnDimensions = (50,),\n",
    "        cellsPerColumn=1,\n",
    "        initialPermanence=0.5,\n",
    "        connectedPermanence=0.5,\n",
    "        minThreshold=8,\n",
    "        maxNewSynapseCount=20,\n",
    "        permanenceIncrement=0.1,\n",
    "        permanenceDecrement=0.0,\n",
    "        activationThreshold=8,\n",
    "        )\n",
    "tm.printParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "テンポラリメモリに供給する入力を作成します。\n",
      "各入力は、アクティブなミニカラムを表します。 \n",
      "ここでは、5つのシーケンスを表すシンプルなSDRを作成します。\n",
      "A -> B -> C -> D -> E  \n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "テンポラリメモリに供給する入力を作成します。\n",
    "各入力は、アクティブなミニカラムを表します。 \n",
    "ここでは、5つのシーケンスを表すシンプルなSDRを作成します。\n",
    "A -> B -> C -> D -> E  \"\"\")\n",
    "dataset = { inp : SDR( tm.numberOfColumns() ) for inp in \"ABCDE\" }\n",
    "dataset['A'].dense[0:10]  = 1   # Input SDR representing \"A\", corresponding to mini-columns 0-9\n",
    "dataset['B'].dense[10:20] = 1   # Input SDR representing \"B\", corresponding to mini-columns 10-19\n",
    "dataset['C'].dense[20:30] = 1   # Input SDR representing \"C\", corresponding to mini-columns 20-29\n",
    "dataset['D'].dense[30:40] = 1   # Input SDR representing \"D\", corresponding to mini-columns 30-39\n",
    "dataset['E'].dense[40:50] = 1   # Input SDR representing \"E\", corresponding to mini-columns 40-49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: A  Bits: 1111111111 0000000000 0000000000 0000000000 0000000000 \n",
      "Input: B  Bits: 0000000000 1111111111 0000000000 0000000000 0000000000 \n",
      "Input: C  Bits: 0000000000 0000000000 1111111111 0000000000 0000000000 \n",
      "Input: D  Bits: 0000000000 0000000000 0000000000 1111111111 0000000000 \n",
      "Input: E  Bits: 0000000000 0000000000 0000000000 0000000000 1111111111 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SDR オブジェクトの高密度データをインプレースで更新したことを通知します\n",
    "for z in dataset.values():\n",
    "  z.dense = z.dense\n",
    "for inp in \"ABCDE\":\n",
    "  print(\"Input:\", inp, \" Bits:\", formatBits( dataset[inp]) )\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "\n",
      "この簡単なシーケンスを学習用の一時記憶装置に送信します\n",
      "\n",
      "計算方法は、学習および/または推論の1つのステップを実行します。注意: ここでは\n",
      "我々は学習を行うだけですが、あなたは予測/推論と学習を行うことができます。\n",
      "望むならば同じステップで（オンライン学習）.\n",
      "\n",
      "Input: A\n",
      ">>> tm.compute()\n",
      "Active cells     1111111111 0000000000 0000000000 0000000000 0000000000 \n",
      "Winner cells     1111111111 0000000000 0000000000 0000000000 0000000000 \n",
      "Predictive cells 0000000000 0000000000 0000000000 0000000000 0000000000 \n",
      "Anomaly 100.0 %\n",
      "\n",
      "Input: B\n",
      ">>> tm.compute()\n",
      "Active cells     0000000000 1111111111 0000000000 0000000000 0000000000 \n",
      "Winner cells     0000000000 1111111111 0000000000 0000000000 0000000000 \n",
      "Predictive cells 0000000000 0000000000 0000000000 0000000000 0000000000 \n",
      "Anomaly 100.0 %\n",
      "\n",
      "Input: C\n",
      ">>> tm.compute()\n",
      "Active cells     0000000000 0000000000 1111111111 0000000000 0000000000 \n",
      "Winner cells     0000000000 0000000000 1111111111 0000000000 0000000000 \n",
      "Predictive cells 0000000000 0000000000 0000000000 0000000000 0000000000 \n",
      "Anomaly 100.0 %\n",
      "\n",
      "Input: D\n",
      ">>> tm.compute()\n",
      "Active cells     0000000000 0000000000 0000000000 1111111111 0000000000 \n",
      "Winner cells     0000000000 0000000000 0000000000 1111111111 0000000000 \n",
      "Predictive cells 0000000000 0000000000 0000000000 0000000000 0000000000 \n",
      "Anomaly 100.0 %\n",
      "\n",
      "Input: E\n",
      ">>> tm.compute()\n",
      "Active cells     0000000000 0000000000 0000000000 0000000000 1111111111 \n",
      "Winner cells     0000000000 0000000000 0000000000 0000000000 1111111111 \n",
      "Predictive cells 0000000000 0000000000 0000000000 0000000000 0000000000 \n",
      "Anomaly 100.0 %\n",
      "\n",
      "リセットコマンドは、シーケンスが終了したことを TM に伝えます。\n",
      "はすべての状態をゼロにします。厳密には必要ではありませんが、ちょっとした\n",
      "リセットなしではもっと難しく、TMはリセットした方が学習が早い.\n",
      "\n",
      ">>> tm.reset()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"################################################################################\")\n",
    "print(\"\")\n",
    "print(\"\"\"この簡単なシーケンスを学習用の一時記憶装置に送信します\"\"\")\n",
    "print(\"\"\"\n",
    "計算方法は、学習および/または推論の1つのステップを実行します。注意: ここでは\n",
    "我々は学習を行うだけですが、あなたは予測/推論と学習を行うことができます。\n",
    "望むならば同じステップで（オンライン学習）.\n",
    "\"\"\")\n",
    "for inp in \"ABCDE\": # 各文字を順番に送る\n",
    "  print(\"Input:\", inp)\n",
    "  activeColumns = dataset[inp]\n",
    "\n",
    "  print(\">>> tm.compute()\")\n",
    "  tm.compute(activeColumns, learn = True)\n",
    "\n",
    "  printStateTM(tm)\n",
    "\n",
    "print(\"\"\"リセットコマンドは、シーケンスが終了したことを TM に伝えます。\n",
    "はすべての状態をゼロにします。厳密には必要ではありませんが、ちょっとした\n",
    "リセットなしではもっと難しく、TMはリセットした方が学習が早い.\n",
    "\"\"\")\n",
    "print(\">>> tm.reset()\")\n",
    "print(\"\")\n",
    "tm.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "\n",
      "ベクトルの同じシーケンスを送り、次のような予測を見てください。\n",
      "テンポラリメモリを使用しています。\n",
      "以下は、アクティブセル、予測セル、アクティブセグメントをプリントアウトした\n",
      "勝者セルです。\n",
      "注目すべきは、アクティブな状態が1であるミニカラムは，現在の入力パターンのSDRと，\n",
      "予測された、次の期待パターンのSDRを表す。\n",
      "\n",
      "Input: A\n",
      ">>> tm.compute()\n",
      "Active cells     1111111111 0000000000 0000000000 0000000000 0000000000 \n",
      "Winner cells     1111111111 0000000000 0000000000 0000000000 0000000000 \n",
      "Predictive cells 0000000000 1111111111 0000000000 0000000000 0000000000 \n",
      "Anomaly 100.0 %\n",
      "\n",
      "Input: B\n",
      ">>> tm.compute()\n",
      "Active cells     0000000000 1111111111 0000000000 0000000000 0000000000 \n",
      "Winner cells     0000000000 1111111111 0000000000 0000000000 0000000000 \n",
      "Predictive cells 0000000000 0000000000 1111111111 0000000000 0000000000 \n",
      "Anomaly 0.0 %\n",
      "\n",
      "Input: C\n",
      ">>> tm.compute()\n",
      "Active cells     0000000000 0000000000 1111111111 0000000000 0000000000 \n",
      "Winner cells     0000000000 0000000000 1111111111 0000000000 0000000000 \n",
      "Predictive cells 0000000000 0000000000 0000000000 1111111111 0000000000 \n",
      "Anomaly 0.0 %\n",
      "\n",
      "Input: D\n",
      ">>> tm.compute()\n",
      "Active cells     0000000000 0000000000 0000000000 1111111111 0000000000 \n",
      "Winner cells     0000000000 0000000000 0000000000 1111111111 0000000000 \n",
      "Predictive cells 0000000000 0000000000 0000000000 0000000000 1111111111 \n",
      "Anomaly 0.0 %\n",
      "\n",
      "Input: E\n",
      ">>> tm.compute()\n",
      "Active cells     0000000000 0000000000 0000000000 0000000000 1111111111 \n",
      "Winner cells     0000000000 0000000000 0000000000 0000000000 1111111111 \n",
      "Predictive cells 0000000000 0000000000 0000000000 0000000000 0000000000 \n",
      "Anomaly 0.0 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"################################################################################\")\n",
    "print(\"\")\n",
    "print(\"\"\"ベクトルの同じシーケンスを送り、次のような予測を見てください。\n",
    "テンポラリメモリを使用しています。\n",
    "以下は、アクティブセル、予測セル、アクティブセグメントをプリントアウトした\n",
    "勝者セルです。\n",
    "注目すべきは、アクティブな状態が1であるミニカラムは，現在の入力パターンのSDRと，\n",
    "予測された、次の期待パターンのSDRを表す。\n",
    "\"\"\")\n",
    "for inp in \"ABCDE\":\n",
    "  print(\"Input:\", inp)\n",
    "  activeColumns = dataset[inp]\n",
    "\n",
    "  print(\">>> tm.compute()\")\n",
    "  tm.compute(activeColumns, learn = False)\n",
    "\n",
    "  printStateTM(tm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit",
   "language": "python",
   "name": "python37164biteddaa04d9bd6403f87a9a26eeb0f918e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
